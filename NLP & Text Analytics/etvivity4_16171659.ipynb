{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "etvivity4_16171659.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGBQ9_CdlbhB"
      },
      "source": [
        "**Name:** Cathaoir Agnew \n",
        "\n",
        "**ID:** 16171659\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwrBWSa5ljdj"
      },
      "source": [
        "# Task 1 \n",
        "**********************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS1j36iGlXFy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "a97ad133-118c-4ef7-b8b4-ff00eb351518"
      },
      "source": [
        "import pandas as pd\n",
        "!pip install jellyfish\n",
        "import jellyfish\n",
        "!wget https://norvig.com/ngrams/count_1w.txt #unigram corpus\n",
        "filePath1 = \"/content/count_1w.txt\"\n",
        "unigrams_df = pd.read_csv(filePath1,sep='\\t',header=None, names=['unigram','count'])\n",
        "print(f'Number of unigrams: {unigrams_df.size}')\n",
        "display(unigrams_df.head(100))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.6/dist-packages (0.8.2)\n",
            "--2020-11-20 12:16:49--  https://norvig.com/ngrams/count_1w.txt\n",
            "Resolving norvig.com (norvig.com)... 158.106.138.13\n",
            "Connecting to norvig.com (norvig.com)|158.106.138.13|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4956241 (4.7M) [text/plain]\n",
            "Saving to: ‘count_1w.txt.1’\n",
            "\n",
            "count_1w.txt.1      100%[===================>]   4.73M  2.95MB/s    in 1.6s    \n",
            "\n",
            "2020-11-20 12:16:52 (2.95 MB/s) - ‘count_1w.txt.1’ saved [4956241/4956241]\n",
            "\n",
            "Number of unigrams: 666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unigram</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the</td>\n",
              "      <td>23135851162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of</td>\n",
              "      <td>13151942776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>and</td>\n",
              "      <td>12997637966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>12136980858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>9081174698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>like</td>\n",
              "      <td>520585287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>service</td>\n",
              "      <td>519537222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>x</td>\n",
              "      <td>508609523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>than</td>\n",
              "      <td>502609275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>find</td>\n",
              "      <td>502043038</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    unigram        count\n",
              "0       the  23135851162\n",
              "1        of  13151942776\n",
              "2       and  12997637966\n",
              "3        to  12136980858\n",
              "4         a   9081174698\n",
              "..      ...          ...\n",
              "95     like    520585287\n",
              "96  service    519537222\n",
              "97        x    508609523\n",
              "98     than    502609275\n",
              "99     find    502043038\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0nEnMQhlwof"
      },
      "source": [
        "# Task 2\n",
        "*******************\n",
        "\n",
        "I have added normalised probabilities of the words and an autocorrection feature, this is not required for the task. This was more of exploration from Arash's advice and can be seen on the forum post. For now I have set the confidence probabilty quite high so it wont autocorrect, but feel free to play around with it yourself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9fW6hsYlwCM"
      },
      "source": [
        "def nonWordSpellingCorrection(nonWord, threshold):\n",
        "  \"\"\" Threshold is the allowed edit distance using damerau levenshtein distance that we will consider for the words. \"\"\"\n",
        "\n",
        "  print(f'nonWord = {nonWord}')\n",
        "\n",
        "  #list to store results \n",
        "  new_word = []\n",
        "  new_frequency = []\n",
        "  new_probability = []\n",
        "  list_of_norm_prob = []\n",
        "\n",
        "  # play around with this value for autocorrect feature\n",
        "  confidence = 0.9999\n",
        "\n",
        "  # calculating total words of the dataframe column of count\n",
        "  total_words =  unigrams_df['count'].sum()\n",
        "\n",
        "  # now we need to look at words that are within some threshold of edit distance \n",
        "  # we will loop through the dataframe, calculate the Distance between non word & the ith  word in the data frame\n",
        "  # if ith word is within a threshold of edit distance, we will add it to a new data frame, and calculate the probability of the word \n",
        "\n",
        "  for i in unigrams_df.unigram:\n",
        "\n",
        "    # if you would like to see values for words that actually exist, just for fun, comment out the below 3 lines\n",
        "\n",
        "    # first check if it is actually a non word \n",
        "    if str(i) == nonWord:\n",
        "      print(f'\\n\"{nonWord}\" is actually a word in the dictionary/dataframe.')\n",
        "      return print(\"\\nTry another word.\")\n",
        "\n",
        "    # now will calculate the edit distance between input nonWord & current word\n",
        "    distance = jellyfish.damerau_levenshtein_distance(nonWord, str(i))\n",
        "\n",
        "    # now set a threshold \n",
        "    if distance <= threshold:\n",
        "\n",
        "      current_word_values = unigrams_df[unigrams_df.unigram == i].values\n",
        "\n",
        "     # store the word \n",
        "      current_word = str(i)\n",
        "\n",
        "     # store the word count \n",
        "      current_word_count = current_word_values[0][1]\n",
        "\n",
        "      # append current word, word count, and its probability\n",
        "      new_word.append(current_word)\n",
        "      new_frequency.append(current_word_count)\n",
        "\n",
        "      # word probability = current word / total number of words counts\n",
        "      new_probability.append( (current_word_count / total_words) )\n",
        "\n",
        "  # create a dataframe of the above\n",
        "  new_dataframe = pd.DataFrame(list(zip(new_word, new_frequency, new_probability )) , columns = [\"Word\", \"Frequency\", 'P(word)'] )\n",
        "\n",
        "  # going to normalize probabilites of new_dataframe \n",
        "  total_probability = new_dataframe['P(word)'].sum()\n",
        "\n",
        "  for j in new_dataframe.Word:\n",
        "\n",
        "    # store values of each row\n",
        "    vals = new_dataframe[new_dataframe.Word == j ].values\n",
        "    # storing probability for each row\n",
        "    prob = vals[0][2]\n",
        "    # nomralizing the probability\n",
        "    norm_prob = prob / total_probability\n",
        "    # append this norm probability to a list\n",
        "    list_of_norm_prob.append(norm_prob)\n",
        "\n",
        "  # this sets dataframe decimal display to 10 decimal points\n",
        "  pd.set_option(\"display.precision\", 10)\n",
        "  # adding list of norm probs to the dataframe as a new column\n",
        "  new_dataframe['Norm Probs'] = list_of_norm_prob\n",
        "\n",
        "  # check to see if max norm probabilty > confidence threshold \n",
        "  if max(list_of_norm_prob) > confidence:\n",
        "\n",
        "    # assigning the max norm probability word to the confidence_word \n",
        "    Confidence_word = new_dataframe.loc[new_dataframe['Norm Probs'].idxmax(), 'Word']\n",
        "    return print(f'\"{Confidence_word}\" above confidence threshold probability, so \"{nonWord}\" autocorrected to \"{Confidence_word}\"')\n",
        "\n",
        "  return new_dataframe"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUHeVg47Rgdz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "5dbdb3bc-721c-44d7-a2d0-ebbaac3fd596"
      },
      "source": [
        "nonWordSpellingCorrection(\"acress\", 1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nonWord = acress\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Frequency</th>\n",
              "      <th>P(word)</th>\n",
              "      <th>Norm Probs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>access</td>\n",
              "      <td>217986984</td>\n",
              "      <td>0.0003706479</td>\n",
              "      <td>0.6854260231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>across</td>\n",
              "      <td>76597151</td>\n",
              "      <td>0.0001302397</td>\n",
              "      <td>0.2408477773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acres</td>\n",
              "      <td>14208905</td>\n",
              "      <td>0.0000241597</td>\n",
              "      <td>0.0446776824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>actress</td>\n",
              "      <td>7010056</td>\n",
              "      <td>0.0000119193</td>\n",
              "      <td>0.0220420262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adress</td>\n",
              "      <td>984657</td>\n",
              "      <td>0.0000016742</td>\n",
              "      <td>0.0030961001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>caress</td>\n",
              "      <td>590047</td>\n",
              "      <td>0.0000010033</td>\n",
              "      <td>0.0018553106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>cress</td>\n",
              "      <td>279364</td>\n",
              "      <td>0.0000004750</td>\n",
              "      <td>0.0008784165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>apress</td>\n",
              "      <td>202431</td>\n",
              "      <td>0.0000003442</td>\n",
              "      <td>0.0006365127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>acess</td>\n",
              "      <td>171785</td>\n",
              "      <td>0.0000002921</td>\n",
              "      <td>0.0005401511</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Word  Frequency       P(word)    Norm Probs\n",
              "0   access  217986984  0.0003706479  0.6854260231\n",
              "1   across   76597151  0.0001302397  0.2408477773\n",
              "2    acres   14208905  0.0000241597  0.0446776824\n",
              "3  actress    7010056  0.0000119193  0.0220420262\n",
              "4   adress     984657  0.0000016742  0.0030961001\n",
              "5   caress     590047  0.0000010033  0.0018553106\n",
              "6    cress     279364  0.0000004750  0.0008784165\n",
              "7   apress     202431  0.0000003442  0.0006365127\n",
              "8    acess     171785  0.0000002921  0.0005401511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQdmkXFQE5Bv"
      },
      "source": [
        "# Task 3 \n",
        "******************************************\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w3oIAUbE7bN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04edfa3-6d4b-46a0-9aa2-8a71d7b87a32"
      },
      "source": [
        "!pip install -U textblob\n",
        "\n",
        "import textblob.download_corpora"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TagJGlieFOgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d38e905-55e7-4bb6-d981-390300a9345e"
      },
      "source": [
        "from textblob import Word\n",
        "\n",
        "def spell_check(word):\n",
        "  if type(word) == str:\n",
        "\n",
        "    w = Word(word)\n",
        "    words_check = w.spellcheck()\n",
        "    print(\"Candidates:\", words_check)\n",
        "    \n",
        "  else: \n",
        "    print(\"Please insert a string\")\n",
        "\n",
        "spell_check('acress')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Candidates: [('across', 0.6851851851851852), ('access', 0.1728395061728395), ('acres', 0.1111111111111111), ('actress', 0.021604938271604937), ('caress', 0.009259259259259259)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ2E--l8M3SW"
      },
      "source": [
        "# Task 4 \n",
        "**************************************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU3eZp_JM6D9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b8ef4a-831a-4ccd-d341-16ffd25f84b4"
      },
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def correct_spell(input_string):\n",
        "  if type(input_string) == str: \n",
        "    \n",
        "    #print out original input\n",
        "    print(f'sentence = {input_string}')\n",
        "\n",
        "    w = TextBlob(input_string)\n",
        "\n",
        "    #correcting it using text blob built in function \n",
        "    corrected = w.correct()\n",
        "    \n",
        "    # printing out corrected sentence\n",
        "    print(\"Corrected sentence = \", corrected)\n",
        "\n",
        "  else: \n",
        "    print(\"Please insert a string\")\n",
        "\n",
        "correct_spell(\"I havv goood speling\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence = I havv goood speling\n",
            "Corrected sentence =  I have good spelling\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}